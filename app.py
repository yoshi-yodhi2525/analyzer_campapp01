import streamlit as st
import pandas as pd
import numpy as np
import spacy
import ginza
from wordcloud import WordCloud
import plotly.graph_objects as go
import plotly.express as px
import networkx as nx
from collections import Counter, defaultdict
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from PIL import Image
import io
import base64
import jaconv
import re
from pyvis.network import Network
import tempfile
import os

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ãƒ•ã‚©ãƒ³ãƒˆãƒ‘ã‚¹ï¼ˆStreamlit Cloudå¯¾å¿œï¼‰
import os
FONT_PATH = os.path.join(os.path.dirname(__file__), "font", "NotoSansJP-VariableFont_wght.ttf")

@st.cache_resource
def load_spacy_model():
    """spaCyãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    try:
        nlp = spacy.load("ja_ginza")
        return nlp
    except OSError:
        st.error("GINZAãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼špip install ja-ginza")
        return None

@st.cache_data
def load_uploaded_data(uploaded_file):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    try:
        if uploaded_file is not None:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã‚’ç¢ºèª
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
                return df
            else:
                st.error("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                return None
        else:
            return None
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

@st.cache_data
def load_default_data():
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆCSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰"""
    try:
        csv_path = os.path.join(os.path.dirname(__file__), "csv", "data.csv")
        if os.path.exists(csv_path):
            # è¤‡æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦è¡Œ
            encodings = ['utf-8', 'shift_jis', 'cp932', 'utf-8-sig']
            df = None
            
            for encoding in encodings:
                try:
                    df = pd.read_csv(csv_path, encoding=encoding)
                    st.write(f"âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {encoding}ï¼‰")
                    break
                except UnicodeDecodeError:
                    continue
            
            if df is None:
                st.error("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’åˆ¤åˆ¥ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                return None
                
            return df
        else:
            st.warning(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
            return None
    except Exception as e:
        st.error(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def preprocess_text(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†"""
    if pd.isna(text):
        return ""
    
    # æ”¹è¡Œã¨ã‚¿ãƒ–ã‚’å‰Šé™¤
    text = re.sub(r'[\n\t\r]', ' ', str(text))
    # é€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«
    text = re.sub(r'\s+', ' ', text)
    # å…¨è§’ãƒ»åŠè§’ã‚’çµ±ä¸€
    text = jaconv.normalize(text, 'NFKC')
    return text.strip()

def extract_keywords(nlp, texts, min_freq=2, pos_tags=['NOUN', 'PROPN', 'ADJ']):
    """å½¢æ…‹ç´ è§£æã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
    all_words = []
    word_pairs = []
    processed_texts = 0
    total_tokens = 0
    filtered_tokens = 0
    
    for text in texts:
        if pd.isna(text) or text.strip() == "":
            continue
            
        processed_texts += 1
        doc = nlp(text)
        words = []
        
        for token in doc:
            total_tokens += 1
            # å“è©ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if token.pos_ in pos_tags and not token.is_stop and len(token.text) > 1:
                # åŸºæœ¬å½¢ã‚’ä½¿ç”¨
                lemma = token.lemma_.lower()
                # æ•°å­—ã‚„è¨˜å·ã®ã¿ã¯é™¤å¤–ï¼ˆæ—¥æœ¬èªæ–‡å­—ã‚’å«ã‚€å ´åˆã¯è¨±å¯ï¼‰
                if not re.match(r'^[a-zA-Z0-9\W]+$', lemma) and len(lemma) >= 2:
                    words.append(lemma)
                    all_words.append(lemma)
                    filtered_tokens += 1
        
        # å…±èµ·ãƒšã‚¢ã‚’æŠ½å‡ºï¼ˆçª“å¹…2ï¼‰
        for i in range(len(words) - 1):
            for j in range(i + 1, min(i + 3, len(words))):
                if words[i] != words[j]:
                    word_pairs.append((words[i], words[j]))
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    st.write(f"ğŸ”§ å‡¦ç†çµ±è¨ˆ:")
    st.write(f"  - å‡¦ç†ã—ãŸãƒ†ã‚­ã‚¹ãƒˆæ•°: {processed_texts}")
    st.write(f"  - ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {total_tokens}")
    st.write(f"  - ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œãƒˆãƒ¼ã‚¯ãƒ³æ•°: {filtered_tokens}")
    st.write(f"  - æŠ½å‡ºå‰ã®å˜èªæ•°: {len(all_words)}")
    
    # é »åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    word_freq = Counter(all_words)
    filtered_words = {word: freq for word, freq in word_freq.items() if freq >= min_freq}
    
    # å…±èµ·ãƒšã‚¢ã®é »åº¦è¨ˆç®—
    pair_freq = Counter(word_pairs)
    filtered_pairs = {pair: freq for pair, freq in pair_freq.items() if freq >= min_freq}
    
    st.write(f"  - æœ€å°å‡ºç¾å›æ•°({min_freq})ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œ: {len(filtered_words)}")
    
    return filtered_words, filtered_pairs

def create_wordcloud(word_freq, font_path):
    """ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ç”Ÿæˆ"""
    if not word_freq:
        return None
    
    try:
        # ãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        if not os.path.exists(font_path):
            st.warning(f"ãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {font_path}")
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨
            wordcloud = WordCloud(
                width=800,
                height=400,
                background_color='white',
                colormap='viridis',
                max_words=100,
                relative_scaling=0.5,
                random_state=42,
                prefer_horizontal=0.9,
                collocations=False,
                regexp=r"[\w\-\u3040-\u309f\u30a0-\u30ff\u4e00-\u9faf]+"
            ).generate_from_frequencies(word_freq)
        else:
            # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨
            wordcloud = WordCloud(
                font_path=font_path,
                width=800,
                height=400,
                background_color='white',
                colormap='viridis',
                max_words=100,
                relative_scaling=0.5,
                random_state=42,
                prefer_horizontal=0.9,
                collocations=False,
                regexp=r"[\w\-\u3040-\u309f\u30a0-\u30ff\u4e00-\u9faf]+"
            ).generate_from_frequencies(word_freq)
        
        return wordcloud
    except Exception as e:
        st.error(f"ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def create_cooccurrence_network(word_pairs, word_freq, min_freq=2):
    """å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½œæˆ"""
    if not word_pairs:
        return None
    
    G = nx.Graph()
    
    # ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
    for word, freq in word_freq.items():
        if freq >= min_freq:
            G.add_node(word, size=freq, freq=freq)
    
    # ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
    for (word1, word2), freq in word_pairs.items():
        if word1 in G and word2 in G:
            G.add_edge(word1, word2, weight=freq)
    
    return G

def plot_network_plotly(G, title="å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"):
    """Plotlyã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å¯è¦–åŒ–"""
    if not G or len(G.nodes()) == 0:
        return None
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨ˆç®—
    pos = nx.spring_layout(G, k=3, iterations=50)
    
    # ã‚¨ãƒƒã‚¸ã®æƒ…å ±
    edge_x = []
    edge_y = []
    edge_info = []
    
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        edge_x.extend([x0, x1, None])
        edge_y.extend([y0, y1, None])
        
        weight = G[edge[0]][edge[1]]['weight']
        edge_info.append(f"{edge[0]} - {edge[1]}<br>å…±èµ·å›æ•°: {weight}")
    
    # ãƒãƒ¼ãƒ‰ã®æƒ…å ±
    node_x = []
    node_y = []
    node_text = []
    node_size = []
    node_color = []
    
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        
        freq = G.nodes[node]['freq']
        node_text.append(f"{node}<br>å‡ºç¾å›æ•°: {freq}")
        node_size.append(max(10, freq * 2))
        node_color.append(freq)
    
    # ã‚¨ãƒƒã‚¸ã®ãƒ—ãƒ­ãƒƒãƒˆ
    edge_trace = go.Scatter(
        x=edge_x, y=edge_y,
        line=dict(width=1, color='#888'),
        hoverinfo='none',
        mode='lines'
    )
    
    # ãƒãƒ¼ãƒ‰ã®ãƒ—ãƒ­ãƒƒãƒˆ
    node_trace = go.Scatter(
        x=node_x, y=node_y,
        mode='markers+text',
        hoverinfo='text',
        text=[node for node in G.nodes()],
        textposition="middle center",
        hovertext=node_text,
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªè¨­å®š
        selected=dict(
            marker=dict(
                color='red',
                size=15
            )
        ),
        unselected=dict(
            marker=dict(
                opacity=0.8
            )
        ),
        marker=dict(
            showscale=True,
            colorscale='Viridis',
            reversescale=True,
            color=node_color,
            size=node_size,
            colorbar=dict(
                thickness=15,
                title="å‡ºç¾å›æ•°",
                xanchor="left"
            ),
            line=dict(width=2, color='black'),
            opacity=1.0
        )
    )
    
    fig = go.Figure(data=[edge_trace, node_trace],
                   layout=go.Layout(
                       title=dict(text=title, font=dict(size=16)),
                       showlegend=False,
                       hovermode='closest',
                       dragmode='pan',  # ãƒ‰ãƒ©ãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’è¨­å®š
                       margin=dict(b=20,l=5,r=5,t=40),
                       annotations=[ dict(
                           text="ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚ºã¯å‡ºç¾å›æ•°ã€è‰²ã¯å…±èµ·ã®å¼·ã•ã‚’è¡¨ã—ã¾ã™ã€‚ãƒã‚¦ã‚¹ãƒ‰ãƒ©ãƒƒã‚°ã§ç§»å‹•ã€ãƒ›ã‚¤ãƒ¼ãƒ«ã§ã‚ºãƒ¼ãƒ å¯èƒ½",
                           showarrow=False,
                           xref="paper", yref="paper",
                           x=0.005, y=-0.002,
                           xanchor="left", yanchor="bottom",
                           font=dict(color="gray", size=12)
                       )],
                       xaxis=dict(
                           showgrid=False, 
                           zeroline=False, 
                           showticklabels=False,
                           scaleanchor="y",  # xè»¸ã¨yè»¸ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’çµ±ä¸€
                           scaleratio=1,
                           constrain="domain"
                       ),
                       yaxis=dict(
                           showgrid=False, 
                           zeroline=False, 
                           showticklabels=False,
                           constrain="domain"
                       ),
                       plot_bgcolor='white',
                       # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªè¨­å®š
                       clickmode='event+select',
                       selectdirection='d'
                   ))
    
    return fig

def plot_network_pyvis(G, title="å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯", height="600px", width="100%"):
    """pyvisã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å¯è¦–åŒ–"""
    if not G or len(G.nodes()) == 0:
        return None
    
    try:
        # pyvisãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½œæˆ
        net = Network(height=height, width=width, bgcolor="#222222", font_color="white")
        
        # ãƒãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
        for node in G.nodes():
            freq = G.nodes[node]['freq']
            # ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚ºã‚’é »åº¦ã«åŸºã¥ã„ã¦èª¿æ•´
            size = max(10, freq * 3)
            # ãƒãƒ¼ãƒ‰ã®è‰²ã‚’é »åº¦ã«åŸºã¥ã„ã¦è¨­å®š
            color_intensity = min(255, freq * 50)
            color = f"rgb({color_intensity}, {255-color_intensity}, 100)"
            
            net.add_node(
                node, 
                label=node,
                size=size,
                color=color,
                title=f"å˜èª: {node}<br>å‡ºç¾å›æ•°: {freq}"
            )
        
        # ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
        for edge in G.edges():
            weight = G[edge[0]][edge[1]]['weight']
            # ã‚¨ãƒƒã‚¸ã®å¤ªã•ã‚’é‡ã¿ã«åŸºã¥ã„ã¦èª¿æ•´
            width = max(1, weight * 2)
            net.add_edge(edge[0], edge[1], width=width, title=f"å…±èµ·å›æ•°: {weight}")
        
        # ç‰©ç†ã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­å®š
        net.set_options("""
        var options = {
          "physics": {
            "enabled": true,
            "stabilization": {"iterations": 100},
            "barnesHut": {
              "gravitationalConstant": -8000,
              "centralGravity": 0.3,
              "springLength": 95,
              "springConstant": 0.04,
              "damping": 0.09,
              "avoidOverlap": 0.1
            }
          },
          "interaction": {
            "hover": true,
            "hoverConnectedEdges": true,
            "selectConnectedEdges": false
          },
          "nodes": {
            "font": {
              "size": 14,
              "color": "white"
            },
            "borderWidth": 2,
            "borderWidthSelected": 4
          },
          "edges": {
            "smooth": {
              "enabled": true,
              "type": "continuous"
            },
            "color": {
              "color": "rgba(255,255,255,0.5)",
              "highlight": "rgba(255,255,255,1)"
            }
          }
        }
        """)
        
        return net
        
    except Exception as e:
        st.error(f"pyvisãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def plot_network_matplotlib(G, layout_type='spring', title="å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯", figsize=(12, 8)):
    """Matplotlibã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å¯è¦–åŒ–"""
    if not G or len(G.nodes()) == 0:
        return None
    
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
    try:
        font_path = FONT_PATH
        # ãƒ•ã‚©ãƒ³ãƒˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’ä½œæˆ
        font_prop = fm.FontProperties(fname=font_path)
        # matplotlibã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆã«è¨­å®š
        plt.rcParams['font.family'] = font_prop.get_name()
        plt.rcParams['axes.unicode_minus'] = False  # ãƒã‚¤ãƒŠã‚¹è¨˜å·ã®æ–‡å­—åŒ–ã‘é˜²æ­¢
    except Exception as e:
        font_prop = None
        plt.rcParams['font.family'] = 'DejaVu Sans'
        st.warning(f"æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    fig, ax = plt.subplots(figsize=figsize)
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨ˆç®—
    layout_functions = {
        'spring': nx.spring_layout,
        'circular': nx.circular_layout,
        'random': nx.random_layout,
        'shell': nx.shell_layout,
        'kamada_kawai': nx.kamada_kawai_layout,
        'spectral': nx.spectral_layout,
        'bipartite': nx.bipartite_layout,
        'planar': nx.planar_layout
    }
    
    if layout_type in layout_functions:
        try:
            if layout_type == 'bipartite':
                # äºŒéƒ¨ã‚°ãƒ©ãƒ•ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®å ´åˆã¯ç‰¹åˆ¥å‡¦ç†
                pos = nx.bipartite_layout(G, list(G.nodes())[:len(G.nodes())//2])
            elif layout_type == 'planar':
                # å¹³é¢ã‚°ãƒ©ãƒ•ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®å ´åˆã¯ç‰¹åˆ¥å‡¦ç†
                pos = nx.planar_layout(G) if nx.is_planar(G) else nx.spring_layout(G)
            else:
                pos = layout_functions[layout_type](G)
        except Exception as e:
            st.warning(f"{layout_type}ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚springãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            pos = nx.spring_layout(G)
    else:
        pos = nx.spring_layout(G)
    
    # ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚ºã¨è‰²ã‚’è¨ˆç®—
    node_sizes = []
    node_colors = []
    node_labels = {}
    
    for node in G.nodes():
        freq = G.nodes[node]['freq']
        # ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚ºã‚’é »åº¦ã«åŸºã¥ã„ã¦èª¿æ•´
        size = max(100, freq * 50)
        node_sizes.append(size)
        node_colors.append(freq)
        node_labels[node] = node
    
    # ã‚¨ãƒƒã‚¸ã‚’æç”»
    nx.draw_networkx_edges(G, pos, alpha=0.5, edge_color='gray', width=0.5, ax=ax)
    
    # ãƒãƒ¼ãƒ‰ã‚’æç”»
    nodes = nx.draw_networkx_nodes(
        G, pos, 
        node_size=node_sizes,
        node_color=node_colors,
        cmap=plt.cm.viridis,
        alpha=0.8,
        ax=ax
    )
    
    # ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ«ã‚’æç”»
    nx.draw_networkx_labels(
        G, pos, 
        labels=node_labels,
        font_size=8,
        font_weight='bold',
        font_properties=font_prop if font_prop else None,
        ax=ax
    )
    
    # ã‚«ãƒ©ãƒ¼ãƒãƒ¼ã‚’è¿½åŠ 
    if nodes:
        plt.colorbar(nodes, ax=ax, label='å‡ºç¾å›æ•°')
    
    # ã‚°ãƒ©ãƒ•ã®è¨­å®š
    ax.set_title(title, fontsize=16, fontweight='bold', pad=20)
    ax.axis('off')
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±ã‚’è¡¨ç¤º
    layout_info = {
        'spring': 'Spring Layout (ãƒãƒãƒ¢ãƒ‡ãƒ«)',
        'circular': 'Circular Layout (å††å½¢)',
        'random': 'Random Layout (ãƒ©ãƒ³ãƒ€ãƒ )',
        'shell': 'Shell Layout (åŒå¿ƒå††)',
        'kamada_kawai': 'Kamada-Kawai Layout',
        'spectral': 'Spectral Layout',
        'bipartite': 'Bipartite Layout (äºŒéƒ¨ã‚°ãƒ©ãƒ•)',
        'planar': 'Planar Layout (å¹³é¢ã‚°ãƒ©ãƒ•)'
    }
    
    ax.text(0.02, 0.98, f'ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ: {layout_info.get(layout_type, layout_type)}', 
            transform=ax.transAxes, fontsize=10, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµ±è¨ˆã‚’è¡¨ç¤º
    stats_text = f'ãƒãƒ¼ãƒ‰æ•°: {len(G.nodes())}\nã‚¨ãƒƒã‚¸æ•°: {len(G.edges())}\nå¯†åº¦: {nx.density(G):.3f}'
    ax.text(0.98, 0.02, stats_text, transform=ax.transAxes, fontsize=10, 
            verticalalignment='bottom', horizontalalignment='right',
            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
    
    plt.tight_layout()
    return fig

def setup_japanese_font():
    """æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š"""
    try:
        font_path = FONT_PATH
        if os.path.exists(font_path):
            font_prop = fm.FontProperties(fname=font_path)
            plt.rcParams['font.family'] = font_prop.get_name()
            plt.rcParams['axes.unicode_minus'] = False
            return True
        else:
            st.warning(f"ãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {font_path}")
            plt.rcParams['font.family'] = 'DejaVu Sans'
            plt.rcParams['axes.unicode_minus'] = False
            return False
    except Exception as e:
        st.warning(f"æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False
        return False

def main():
    st.title("ğŸ“Š ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª")
    st.markdown("---")
    
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
    font_setup_success = setup_japanese_font()
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.subheader("ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
    uploaded_file = st.file_uploader(
        "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=['csv'],
        help="ãƒ†ã‚­ã‚¹ãƒˆåˆ†æç”¨ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã‚’å«ã‚€å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
    )
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§data.csvã‚’èª­ã¿è¾¼ã¿ï¼‰
    df = load_default_data()
    
    if df is not None:
        st.success("ğŸ“‹ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆdata.csvï¼‰ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
        st.info("ğŸ’¡ ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€ä¸Šè¨˜ã‹ã‚‰CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.warning("âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯ä¸Šæ›¸ã
    if uploaded_file is not None:
        uploaded_df = load_uploaded_data(uploaded_file)
        if uploaded_df is not None:
            df = uploaded_df
            st.success("ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    
    if df is None:
        st.error("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return
    
    # spaCyãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    nlp = load_spacy_model()
    if nlp is None:
        return
    
    st.sidebar.header("âš™ï¸ è¨­å®š")
    
    # ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿æ¦‚è¦")
    
    # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¡¨ç¤º
    if uploaded_file is not None:
        st.info(f"ğŸ“ ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{uploaded_file.name}ã€")
    else:
        st.info("ğŸ“‹ ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆdata.csvï¼‰")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ç·è¡Œæ•°", len(df))
    
    with col2:
        st.metric("ç·åˆ—æ•°", len(df.columns))
        st.caption(f"åˆ—å: {', '.join(df.columns.tolist())}")
    
    with col3:
        # ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã®é¸æŠï¼ˆã‚ˆã‚ŠæŸ”è»Ÿãªæ¤œå‡ºï¼‰
        text_columns = []
        for col in df.columns:
            # æ–‡å­—åˆ—å‹ã¾ãŸã¯æ•°å€¤å‹ã§ã‚‚æ–‡å­—åˆ—ã¨ã—ã¦æ‰±ãˆã‚‹åˆ—ã‚’æ¤œå‡º
            if (df[col].dtype == 'object' or 
                (df[col].dtype in ['int64', 'float64'] and df[col].astype(str).str.len().mean() > 5)):
                text_columns.append(col)
        
        # æ˜ç¤ºçš„ã«'text'åˆ—ãŒã‚ã‚‹å ´åˆã¯å„ªå…ˆ
        if 'text' in df.columns and 'text' not in text_columns:
            text_columns.insert(0, 'text')
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
        st.write(f"ğŸ” æ¤œå‡ºã•ã‚ŒãŸåˆ—: {list(df.columns)}")
        st.write(f"ğŸ” ãƒ‡ãƒ¼ã‚¿å‹: {dict(df.dtypes)}")
        st.write(f"ğŸ” ãƒ†ã‚­ã‚¹ãƒˆåˆ—å€™è£œ: {text_columns}")
        
        if text_columns:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§'text'åˆ—ã‚’é¸æŠï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
            default_index = 0
            if 'text' in text_columns:
                default_index = text_columns.index('text')
            
            selected_text_column = st.selectbox(
                "åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã‚’é¸æŠ",
                text_columns,
                index=default_index,
                help="ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚’è¡Œã†åˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„"
            )
            
            # é¸æŠã•ã‚ŒãŸåˆ—ã®æœ‰åŠ¹ãƒ†ã‚­ã‚¹ãƒˆæ•°ã‚’è¨ˆç®—
            non_empty_texts = df[selected_text_column].dropna().astype(str).str.strip()
            non_empty_texts = non_empty_texts[non_empty_texts != '']
            st.metric("æœ‰åŠ¹ãƒ†ã‚­ã‚¹ãƒˆæ•°", len(non_empty_texts))
            
            # é¸æŠã•ã‚ŒãŸåˆ—ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤º
            st.write(f"ğŸ“ é¸æŠã•ã‚ŒãŸåˆ—ã€Œ{selected_text_column}ã€ã®ã‚µãƒ³ãƒ—ãƒ«:")
            sample_data = df[selected_text_column].dropna().head(3).tolist()
            for i, text in enumerate(sample_data, 1):
                st.write(f"  {i}. {str(text)[:50]}...")
        else:
            st.warning("ãƒ†ã‚­ã‚¹ãƒˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.write("åˆ©ç”¨å¯èƒ½ãªåˆ—ã¨ãã®ãƒ‡ãƒ¼ã‚¿å‹:")
            for col in df.columns:
                st.write(f"  - {col}: {df[col].dtype}")
            return
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    st.subheader("ğŸ‘€ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    if st.checkbox("ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", value=False):
        st.dataframe(df.head(10), use_container_width=True)
        
        # é¸æŠã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆåˆ—ã®ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        if 'selected_text_column' in locals():
            st.subheader(f"ğŸ“ {selected_text_column}åˆ—ã®ã‚µãƒ³ãƒ—ãƒ«")
            sample_texts = df[selected_text_column].dropna().head(5).tolist()
            for i, text in enumerate(sample_texts, 1):
                st.write(f"{i}. {text[:100]}{'...' if len(str(text)) > 100 else ''}")
    
    # è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    min_freq = st.sidebar.slider("æœ€å°å‡ºç¾å›æ•°", 1, 10, 1)
    max_words = st.sidebar.slider("æœ€å¤§å˜èªæ•°", 50, 200, 100)
    
    # å“è©é¸æŠ
    pos_options = {
        'åè©': 'NOUN',
        'å›ºæœ‰åè©': 'PROPN', 
        'å½¢å®¹è©': 'ADJ',
        'å‹•è©': 'VERB'
    }
    
    selected_pos = st.sidebar.multiselect(
        "åˆ†æå¯¾è±¡ã®å“è©",
        options=list(pos_options.keys()),
        default=['åè©', 'å›ºæœ‰åè©', 'å½¢å®¹è©', 'å‹•è©']
    )
    
    selected_pos_tags = [pos_options[pos] for pos in selected_pos]
    
    # ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
    if 'selected_text_column' in locals():
        texts = df[selected_text_column].apply(preprocess_text).tolist()
        
        with st.spinner("å½¢æ…‹ç´ è§£æã‚’å®Ÿè¡Œä¸­..."):
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
            st.write(f"ğŸ“Š å‡¦ç†å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆæ•°: {len(texts)}")
            st.write(f"ğŸ“ æœ€åˆã®3ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«:")
            for i, text in enumerate(texts[:3], 1):
                st.write(f"  {i}. {text[:100]}{'...' if len(text) > 100 else ''}")
            
            word_freq, word_pairs = extract_keywords(
                nlp, texts, min_freq, selected_pos_tags
            )
            
            # æŠ½å‡ºçµæœã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±
            st.write(f"ğŸ” æŠ½å‡ºã•ã‚ŒãŸå˜èªæ•°: {len(word_freq)}")
            st.write(f"ğŸ”— æŠ½å‡ºã•ã‚ŒãŸå…±èµ·ãƒšã‚¢æ•°: {len(word_pairs)}")
            
            if word_freq:
                st.write("ğŸ“ˆ ä¸Šä½10å˜èª:")
                top_words = dict(Counter(word_freq).most_common(10))
                for word, freq in top_words.items():
                    st.write(f"  - {word}: {freq}å›")
            else:
                st.warning("âš ï¸ å˜èªãŒæŠ½å‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š")
                st.write("- ãƒ†ã‚­ã‚¹ãƒˆã«æ—¥æœ¬èªãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹")
                st.write("- æœ€å°å‡ºç¾å›æ•°ã®è¨­å®šãŒé«˜ã™ããªã„ã‹")
                st.write("- é¸æŠã—ãŸå“è©ãŒé©åˆ‡ã‹")
        
        # çµæœè¡¨ç¤º
        st.subheader("ğŸ“ˆ åˆ†æçµæœ")
        
        if word_freq:
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ğŸ”¤ ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰")
                
                # ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆ
                wordcloud = create_wordcloud(word_freq, FONT_PATH)
                if wordcloud:
                    fig_wc, ax_wc = plt.subplots(figsize=(10, 5))
                    ax_wc.imshow(wordcloud, interpolation='bilinear')
                    ax_wc.axis('off')
                    st.pyplot(fig_wc)
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                    img_buffer = io.BytesIO()
                    plt.savefig(img_buffer, format='png', bbox_inches='tight', dpi=300)
                    img_buffer.seek(0)
                    
                    st.download_button(
                        label="ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=img_buffer.getvalue(),
                        file_name="wordcloud.png",
                        mime="image/png"
                    )
                else:
                    st.warning("ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            
            with col2:
                st.subheader("ğŸ“Š é »å‡ºå˜èªãƒˆãƒƒãƒ—20")
                
                # é »å‡ºå˜èªè¡¨ç¤º
                top_words = dict(Counter(word_freq).most_common(20))
                
                for i, (word, freq) in enumerate(top_words.items(), 1):
                    st.write(f"{i:2d}. **{word}** ({freq}å›)")
            
            # å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
            st.subheader("ğŸ•¸ï¸ å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯")
            
            if word_pairs:
                G = create_cooccurrence_network(word_pairs, word_freq, min_freq)
                if G and len(G.nodes()) > 0:
                    # å¯è¦–åŒ–æ–¹æ³•ã‚’é¸æŠ
                    viz_type = st.radio(
                        "å¯è¦–åŒ–æ–¹æ³•ã‚’é¸æŠ",
                        ["pyvis (é«˜åº¦ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–)", "Plotly (ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–)", "Matplotlib (é™çš„)"],
                        horizontal=True
                    )
                    
                    if viz_type == "pyvis (é«˜åº¦ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–)":
                        # pyvisãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è¨­å®š
                        col1, col2 = st.columns(2)
                        with col1:
                            height = st.selectbox("è¡¨ç¤ºé«˜ã•", ["400px", "500px", "600px", "700px", "800px"], index=2)
                        with col2:
                            physics = st.selectbox("ç‰©ç†ã‚¨ãƒ³ã‚¸ãƒ³", ["æœ‰åŠ¹", "ç„¡åŠ¹"], index=0)
                        
                        # pyvisãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”Ÿæˆ
                        with st.spinner("pyvisãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”Ÿæˆä¸­..."):
                            net = plot_network_pyvis(G, height=height)
                        
                        if net:
                            # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                            with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
                                net.save_graph(f.name)
                                html_file = f.name
                            
                            try:
                                # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§è¡¨ç¤º
                                with open(html_file, 'r', encoding='utf-8') as f:
                                    html_content = f.read()
                                
                                # ç‰©ç†ã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­å®šã‚’å‹•çš„ã«å¤‰æ›´
                                if physics == "ç„¡åŠ¹":
                                    html_content = html_content.replace('"enabled": true', '"enabled": false')
                                
                                st.components.v1.html(html_content, height=int(height.replace('px', '')) + 50)
                                
                            finally:
                                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                                try:
                                    os.unlink(html_file)
                                except OSError:
                                    pass  # ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å‰Šé™¤ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ç„¡è¦–
                        else:
                            st.warning("pyvisãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    
                    elif viz_type == "Plotly (ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–)":
                        fig_net = plot_network_plotly(G, "å˜èªã®å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯")
                        if fig_net:
                            st.plotly_chart(fig_net, use_container_width=True)
                        else:
                            st.warning("Plotlyãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    
                    else:  # Matplotlib
                        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆé¸æŠ
                        layout_options = {
                            'Spring Layout (ãƒãƒãƒ¢ãƒ‡ãƒ«)': 'spring',
                            'Circular Layout (å††å½¢)': 'circular',
                            'Random Layout (ãƒ©ãƒ³ãƒ€ãƒ )': 'random',
                            'Shell Layout (åŒå¿ƒå††)': 'shell',
                            'Kamada-Kawai Layout': 'kamada_kawai',
                            'Spectral Layout': 'spectral',
                            'Bipartite Layout (äºŒéƒ¨ã‚°ãƒ©ãƒ•)': 'bipartite',
                            'Planar Layout (å¹³é¢ã‚°ãƒ©ãƒ•)': 'planar'
                        }
                        
                        selected_layout = st.selectbox(
                            "ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’é¸æŠ",
                            options=list(layout_options.keys()),
                            index=0
                        )
                        
                        layout_type = layout_options[selected_layout]
                        
                        # å›³ã®ã‚µã‚¤ã‚ºè¨­å®š
                        fig_size = st.slider("å›³ã®ã‚µã‚¤ã‚º", 8, 16, 12)
                        
                        # Matplotlibãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æç”»
                        with st.spinner(f"{selected_layout}ã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”Ÿæˆä¸­..."):
                            fig_matplotlib = plot_network_matplotlib(
                                G, 
                                layout_type=layout_type,
                                title=f"å˜èªã®å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ - {selected_layout}",
                                figsize=(fig_size, fig_size * 0.7)
                            )
                        
                        if fig_matplotlib:
                            st.pyplot(fig_matplotlib)
                            
                            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                            img_buffer = io.BytesIO()
                            fig_matplotlib.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')
                            img_buffer.seek(0)
                            
                            st.download_button(
                                label="ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=img_buffer.getvalue(),
                                file_name=f"network_{layout_type}.png",
                                mime="image/png"
                            )
                        else:
                            st.warning("Matplotlibãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    
                    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµ±è¨ˆï¼ˆä¸¡æ–¹ã®å¯è¦–åŒ–ã§å…±é€šï¼‰
                    st.subheader("ğŸ“Š ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµ±è¨ˆ")
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ãƒãƒ¼ãƒ‰æ•°", len(G.nodes()))
                    with col2:
                        st.metric("ã‚¨ãƒƒã‚¸æ•°", len(G.edges()))
                    with col3:
                        st.metric("å¯†åº¦", f"{nx.density(G):.3f}")
                    with col4:
                        if len(G.nodes()) > 0:
                            degree_centrality = nx.degree_centrality(G)
                            max_centrality_node = max(degree_centrality, key=degree_centrality.get)
                            st.metric("ä¸­å¿ƒæ€§æœ€å¤§", max_centrality_node)
                    
                    # ä¸­å¿ƒæ€§åˆ†æ
                    if len(G.nodes()) > 0:
                        st.subheader("ğŸ¯ ä¸­å¿ƒæ€§åˆ†æ")
                        
                        # å„ç¨®ä¸­å¿ƒæ€§ã‚’è¨ˆç®—
                        degree_centrality = nx.degree_centrality(G)
                        betweenness_centrality = nx.betweenness_centrality(G)
                        closeness_centrality = nx.closeness_centrality(G)
                        
                        # ä¸Šä½5ä½ã‚’è¡¨ç¤º
                        top_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:5]
                        top_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]
                        top_closeness = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]
                        
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.write("**æ¬¡æ•°ä¸­å¿ƒæ€§**")
                            for i, (node, centrality) in enumerate(top_degree, 1):
                                st.write(f"{i}. {node}: {centrality:.3f}")
                        
                        with col2:
                            st.write("**åª’ä»‹ä¸­å¿ƒæ€§**")
                            for i, (node, centrality) in enumerate(top_betweenness, 1):
                                st.write(f"{i}. {node}: {centrality:.3f}")
                        
                        with col3:
                            st.write("**è¿‘æ¥ä¸­å¿ƒæ€§**")
                            for i, (node, centrality) in enumerate(top_closeness, 1):
                                st.write(f"{i}. {node}: {centrality:.3f}")
                        
                else:
                    st.warning("å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.warning("å…±èµ·ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.warning("åˆ†æå¯¾è±¡ã®å˜èªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è¨­å®šã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.error("ãƒ†ã‚­ã‚¹ãƒˆåˆ—ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: gray;'>
        ğŸ“Š ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª | Powered by Streamlit, GINZA, WordCloud, NetworkX
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()
